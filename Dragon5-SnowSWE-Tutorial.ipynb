{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff608027",
   "metadata": {},
   "source": [
    "# Dragon 5 Snow Water Equivalent Tutorial\n",
    "\n",
    "Welcome! I am Dr. Mel Sandells and look forward to working with you on development of Snow Water Equivalent retrievals from passive microwave data. We will use the Snow Microwave Radiative Transfer (SMRT) model to investigate the sensitivity of microwave emission to snow properties and develop your own SWE retrieval algorithm. We will then apply this to data from AMSR2 and see how well your retrieval algorithm compares with measured data.\n",
    "\n",
    "In this tutorial, we will:\n",
    "- Use the Chang algorithm to calculate SWE\n",
    "- Compare with observations of snow mass\n",
    "- Simulate microwave emission with SMRT and re-derive the Chang algorithm\n",
    "- Explore sources of error due to snowpack properties\n",
    "\n",
    "\n",
    "We will use the SMRT model and field observations from the Dai papers below with python and jupyter notebooks. The field campaign took place between 27 November 2015 to 25 March 2016 at the Altay National Reference Meteorological station (ANRMS), which is approximately 6 km from the foot of the Altay Mountains in Northwest China.\n",
    "\n",
    "*References used in this work*\n",
    "\n",
    "Chang, A., Foster, J., & Hall, D. (1987). Nimbus-7 SMMR Derived Global Snow Cover Parameters. Annals of Glaciology, 9, 39-44. doi:10.3189/S0260305500200736\n",
    "\n",
    "Dai, L. (2020). Microwave radiometry experiment for snow in Altay China: in situ time series of data for electromagnetic and physical features of snow pack and environment. National Tibetan Plateau / Third Pole Environment Data Center. https://doi.org/10.11888/Snow.tpdc.270886.\n",
    "\n",
    "Dai, L.Y., Che, T., Xiao, L.et al. (2022) Improving the snow volume scattering algorithm in a microwave forward model by using ground-based remote sensing snow observation. IEEE Transactions on Geoscience and Remote Sensing, 60, 4300617\n",
    "\n",
    "Dai, L., Che, T., Zhang, Y., Ren, Z., Tan, J., Akynbekkyzy, M., Xiao, L., Zhou, S., Yan, Y., Liu, Y., Li, H., and Wang, L. (2022). Microwave radiometry experiment for snow in Altay, China: time series of in situ data for electromagnetic and physical features of snowpack. Earth Syst. Sci. Data, 14, 3509–3530, doi: 10.5194/essd-14-3509-2022.\n",
    "\n",
    "James L. Foster, Chaojiao Sun, Jeffrey P. Walker, Richard Kelly, Alfred Chang, Jiarui Dong, Hugh Powell,\n",
    "Quantifying the uncertainty in passive microwave snow water equivalent observations, Remote Sensing of Environment,\n",
    "Volume 94, Issue 2, 2005, 187-203, https://doi.org/10.1016/j.rse.2004.09.012.\n",
    "\n",
    "Sandells, Melody, Henning Löwe, Ghislain Picard, Marie Dumont, Richard Essery, Nicolas Floury, Anna Kontu, Juha Lemmetyinen, William Maslanka, Samuel Morin, Andreas Wiesmann, Christian Mätzler, X-ray tomography-based microstructure representation in the Snow Microwave Radiative Transfer model, IEEE Transactions on Geoscience and Remote Sensing, https://dx.doi.org/10.1109/TGRS.2021.3086412, 2021.\n",
    "\n",
    "\n",
    "## Use Chang algorithm to calculate SWE\n",
    "\n",
    "The 'Chang algorithm' is often quoted as\n",
    "\n",
    "SWE (mm) = 4.77 * (TB18H - TB36H)\n",
    "\n",
    "where the horizontally polarized brightness temperatures at 18 GHz (TB18H) and 36 GHz (TB36H) are in Kelvin (e.g. Foster et al., 2005). However, if you go back to the original paper, equation 1 of Chang et al. (1987) states that\n",
    "\n",
    "SD = 1.59 * (TB18H - TB36H) cm.\n",
    "\n",
    "There is already an assumption that has been applied to convert snow depth (SD) in cm to SWE in mm. <mark>What is the density that has been assumed?</mark>\n",
    "\n",
    "mass = density * volume\n",
    "\n",
    "<mark>SWE [kg m<sup>-2</sup>] = density * SD [m]</mark>\n",
    "\n",
    "Note: SWE units of mm are equivalent to kg m<sup>-2</sup>: use density of liquid water = 1000 kg m<sup>-2</sup> over 1 m<sup>3</sup> volume in the equation above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000209ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate assumed density. First convert Chang depth and SWE coefficients into SI units.\n",
    "\n",
    "density = 4.77 * 1e3 / (1.59 * 10)\n",
    "print (density)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded8e1e",
   "metadata": {},
   "source": [
    "So there is already an assumption that all snow has a density of 300 kg m<sup>-2</sup>. This is named in the Chang paper, so that's good. \n",
    "\n",
    "Let's have a look at some measured data from Dai, L. (2020). These data have already been downloaded for you so let's load them. They are in netCDF format so we will import a package to read them, along with some other standard packages for analysis and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f5598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320224e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read snowpit data\n",
    "ds_snow = xr.open_dataset('Dragon5DataSnowSWE/daily_snow_pit_data.nc')\n",
    "# See what's inside\n",
    "print (list(ds_snow.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c0316",
   "metadata": {},
   "source": [
    "There are a lot of variables in this dataset! For now, we'll look at the density integrated over the whole snowpack. This is the 'Snow Tube' variable, which has units of g cm<sup>-3</sup> in the input file (see readme.docx in the Dragon5DataSnowSWE folder). We'll convert it to SI units and plot it as a function of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds_snow['time'].values, ds_snow['Snow Tube'].values*1e3)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Density [kg m$^{-3}$]')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3792921",
   "metadata": {},
   "source": [
    "<mark>When do you think the algorithm might work best?</mark>\n",
    "\n",
    "Next, we'll create a new variable to store SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWE in mm = depth in m * density in kg m-3\n",
    "SWE_mm = (ds_snow['Snow depth'].values / 100) * ds_snow['Snow Tube'].values * 1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71e4ec",
   "metadata": {},
   "source": [
    "Adapt the code from above to plot SWE vs time to show what you hope the algorithm will be able to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beef93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7374ebe",
   "metadata": {},
   "source": [
    "We'll load in the in-situ measured brightness temperature. Note that the Chang algorithm was designed to work at an incidence angle of 50 degrees. We will select all data between 45 and 55 deg incidence angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e80add",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_data = xr.open_dataset('Dragon5DataSnowSWE/TBdata-multianglen.nc')\n",
    "mask = (tb_data['incidence angle'].values > -55) & (tb_data['incidence angle'].values < -45)\n",
    "tb_final = tb_data.sel(time=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a4a6f",
   "metadata": {},
   "source": [
    "Now we perform the Chang retrieval algorithm on these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chang_swe = 4.77 * (tb_final.Tb18h - tb_final.TB36h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09554169",
   "metadata": {},
   "source": [
    "Note the change in naming convention between frequencies (Tb or TB). When developing a dataset, you can save yourself time with consistent naming - this makes it easier to automate the processing code.\n",
    "\n",
    "## Compare with observations of snow mass\n",
    "\n",
    "\n",
    "Plot both Chang_swe and measured SWE against time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2413b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec9e7840",
   "metadata": {},
   "source": [
    "<mark>What do you think of the algorithm performance? When does it work the best?</mark>\n",
    "\n",
    "## Simulate microwave emission with SMRT and re-derive the Chang algorithm\n",
    "\n",
    "We are trying to recreate this figure:\n",
    "\n",
    "<img src=\"Dragon5DataSnowSWE/Chang.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d2923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few SMRT imports to help you build the snowpack, sensor, substrate and model\n",
    "from smrt import make_model, make_snowpack, sensor_list, make_soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a simple snowpack\n",
    "radius = 0.3e-3\n",
    "density= 300\n",
    "temperature = 260\n",
    "sp = make_snowpack(thickness=[1], microstructure_model='sticky_hard_spheres',\n",
    "                  density=density, radius=radius, temperature=temperature,\n",
    "                  stickiness=0.15)\n",
    "\n",
    "# Make a simple soil underneath\n",
    "soil = make_soil('soil_wegmuller', 'dobson85', temperature=265, roughness_rms=0.25, \n",
    "                 moisture=0.25, sand=0.01, clay=0.7, drymatter=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1de7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the snow on top of the soil\n",
    "snow = sp + soil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d61c9",
   "metadata": {},
   "source": [
    "If we wanted to, we could make an atmosphere and add it with \n",
    "\n",
    "```snow = atmos + sp + soil```\n",
    "\n",
    "or put snow on top of sea ice e.g.\n",
    "\n",
    "```medium = sp + sea_ice```\n",
    "\n",
    "For now, we will stick with snow on top of soil, but SMRT tutorials are available on https://github.com/smrt-model/tutorials for atmosphere and sea ice.\n",
    "\n",
    "\n",
    "Now we specify the model configuration. We need to choose an electromagnetic model (Here, the Improved Born Approximation model 'iba') and a method to solve the radiative transfer equation (here, the Discrete Ordinates Radiative Transfer solver 'dort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d22706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "model = make_model(\"iba\", \"dort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89073c",
   "metadata": {},
   "source": [
    "Next, we need to specify the sensor. We have several pre-built sensors available e.g. CryoSat-2, AMSRE but we'll use the generic passive sensor as this is unique to the field campaign. If you want, you can expand the frequency list to include all field measurements, or incidence angle list to look at different incidence angles. Here we will look at two frequencies and one incidence angle. <mark>NOTE: all inputs to SMRT are in SI units with no exceptions.</mark> Frequencies will be in Hz, not GHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b95ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [18e9, 36e9]\n",
    "incidence_angle = 50\n",
    "\n",
    "radiometer = sensor_list.passive(frequencies, incidence_angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c381b",
   "metadata": {},
   "source": [
    "Now we run the model for the sensor looking at the snowpack and look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.run(radiometer, snow)\n",
    "print (results.TbH().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56731007",
   "metadata": {},
   "source": [
    "<mark>Note that the brightness temperature at 18 GHz is higher than 36 GHz. Why do you think this is?</mark>\n",
    "\n",
    "\n",
    "SMRT can also be run in active (simulate backscatter) or altimeter mode (simulate altimeter waveform). For active, you can simply specify a different sensor e.g.\n",
    "\n",
    "``` \n",
    "scatterometer = sensor_list.active(frequencies, incidence_angle)\n",
    "active_results = model.run(scatterometer, sp)\n",
    "print (active_results. sigmaHH_dB()) \n",
    "```\n",
    "\n",
    "Here we have not specified a substrate because the soil model used is for passive. The model has only been run for the snow. You may get a warning that the snowpack is too thin: this indicates radiation may be lost at the bottom of the snowpack. Details on how to use an active model are included in the SMRT Tutorials on GitHub.\n",
    "\n",
    "For altimeter results, you need a time-dependent radiative transfer solution technique so would have to change the model e.g. \n",
    "\n",
    "``` \n",
    "altimeter_model = make_model('iba', 'nadir_lrm_altimetry')\n",
    "from smrt.inputs.altimeter_list import sentinel3_sral\n",
    "s3 = sentinel3_sral()\n",
    "altimeter_result = altimeter_model.run(s3, sp)\n",
    "plt.plot(altimeter_result.t_gate*1e9, altimeter_result.sigma())\n",
    "```\n",
    "\n",
    "To recreate the Chang algorithm we need to specify brightness temperatures for a range of SWE. We will generate a list of snowpacks and run the model on them. The maximum SWE in the Chang algorithm is 100cm (1000mm). With a snow density of 300 kg m$^{-3}$, this is equivalent to a snow depth of 3.3m. We will generate an array of snowdepths up to 3.4 m in increments of 0.1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae590800",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowdepths = np.arange(0.1, 3.5, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbe289",
   "metadata": {},
   "source": [
    "Use *list comprehension* to generate a list of snowpacks! Then check the parameters are as you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpacks = [make_snowpack(thickness=[d], microstructure_model='sticky_hard_spheres',\n",
    "                  density=density, radius=radius, temperature=temperature,\n",
    "                  stickiness=0.15) + soil for d in snowdepths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first snowpack in the list (index is 0). If you want to plot the last snowpack in the list, use index = -1.\n",
    "snowpacks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b40ed3",
   "metadata": {},
   "source": [
    "Now run the passive model with the radiometer sensor on a list of snowpacks and plot the results for 18 GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = model.run(radiometer, snowpacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e52812",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(snowdepths, results_all.TbH(frequency=18e9), label='18GHz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3895ad3",
   "metadata": {},
   "source": [
    "Now add in the 36GHz results to the graph above and add axes labels and a legend ```plt.legend()```\n",
    "\n",
    "\n",
    "It should start to look something like the left hand side Chang figure above. If you wanted to really recreate it, you could expand the list of frequencies and re-run the simulations. You could also generate a second graph with a grain radius of 0.6mm.\n",
    "\n",
    "The Chang algorithm is based on the brightness temperature difference: for simplicity let's plot this brightness temperature difference against depth, find the slope of the graph and hopefully find the 1.59 coefficient in the original Chang algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_diff = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a64228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a scatterplot\n",
    "plt.scatter(snowdepths*1e2, tb_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acea734",
   "metadata": {},
   "source": [
    "Why does the graph look like this? What is happening in deeper snow? How would you fit a best-line fit to this? Note that the algorithm should run close to the origin i.e. no difference in brightness temperature means snow snow.\n",
    "\n",
    "Use ```fit = np.polyfit(snowdepths[0:2]*1e2, tb_diff[0:2], deg=1)``` but think about what range you would like to apply this over. This code will only fit to the first two values.\n",
    "\n",
    "\n",
    "Add the fitted line to the graph above with this code:\n",
    "```plt.plot(snowdepths, fit[0] * snowdepths + fit[1], 'k--', alpha=0.5)```\n",
    "\n",
    "Don't forget to add in axis labels too!\n",
    "\n",
    "The gradient (coefficient) is then the fit[0] parameter. What is your coefficient?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (fit[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99fff0",
   "metadata": {},
   "source": [
    "<mark>Does it equal 1.59? Why not? What about for a grain radius of 0.6mm? How do you think the Chang algorithm was derived?</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41daa1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb108e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69ade07f",
   "metadata": {},
   "source": [
    "So perhaps you have derived an algorithm close to the Chang algorithm, yet the graph you plotted with measured SWE shows a large overestimation for higher SWE. Is the model doing a good job at simulating brightness temperature? Let's check. Use the measured depths to create a new list of snowpacks for each measurement time.\n",
    "\n",
    "Note we will need to skip the one snowdepth recorded as NaN. We will use a mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ccf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick only values that are not NaN\n",
    "nan_mask = ~np.isnan(ds_snow['Snow depth'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB /100 converts from measured units of cm to SI units needed in SMRT\n",
    "snowpacks_obs_depth = [make_snowpack(thickness=[d], microstructure_model='sticky_hard_spheres',\n",
    "                  density=density, radius=radius, temperature=temperature,\n",
    "                  stickiness=0.15) + soil for d in (ds_snow['Snow depth'].values[nan_mask] / 100)]\n",
    "\n",
    "\n",
    "results_obs_depths = model.run(radiometer, snowpacks_obs_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.plot(tb_final.time, tb_final.Tb18h, 'bx', label='Observed 18GHz')\n",
    "plt.plot(ds_snow.time[nan_mask], results_obs_depths.TbH(frequency=18e9), 'ro', label='Simulated 18GHz')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('TB[K]')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b9ed89",
   "metadata": {},
   "source": [
    "Add in the results for 36 GHz. <mark>Do the model results compare well with observations? Why?</mark>\n",
    "\n",
    "\n",
    "## Explore sources of error due to snowpack properties\n",
    "\n",
    "How do the snowpack observations compare with what we have assumed? Let's take 3rd February 2016, where the retrieval algorithm doesn't work so well and we have observations of brightness temperature. We'll subset the snow data and look at the multiple layer properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_date = ds_snow['time'][68].values\n",
    "\n",
    "snow_3Feb = ds_snow.sel(time=selected_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004356f",
   "metadata": {},
   "source": [
    "Have a look at the properties of each layer (1-4). Note these may not be in SI units. Temperature information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('thickness of layer 1 (cm)', snow_3Feb.thickness_layer1.values)\n",
    "print('snow density to 5cm (g/cm3)', snow_3Feb['snow fork_5 cm'].values)\n",
    "print('long axis grain extent in layer 1 (mm)', snow_3Feb['long_layer1'].values)\n",
    "print('short axis grain extent in layer 1 (mm)', snow_3Feb['short_layer1'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0b0f5",
   "metadata": {},
   "source": [
    "Snow temperature data are held in a different file. We'll import it and set the date to the closest observed TB time (3rd Feb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read temperature data\n",
    "temp_data = xr.open_dataset('Dragon5DataSnowSWE/ten-minute_4_component_radiation_and_snow temperature.nc')\n",
    "# See what's inside\n",
    "print (list(temp_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa954d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just confirms the index used will give the same date: they should all be 3rd Feb 2016.\n",
    "print (selected_date)\n",
    "print (tb_final.time[64].values)\n",
    "print(temp_data['time'][10540].values)\n",
    "snow_temperature = temp_data.sel(time=temp_data['time'][10540].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39730d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check temperature at bottom of snowpack\n",
    "print (snow_temperature.Snow_T_0cm.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fd3d74",
   "metadata": {},
   "source": [
    "Have a look at the properties of the different layers. We'll need thickness, density, temperature and grain radius. There is a slight complication because the layers follow the natural stratigraphy of the snowpack, the snow fork density measurements and temperatures are made every 5cm, so you'll need to make some modelling assumptions and decide how to deal with this. To simulate a multilayer snowpack with SMRT, just specify lists for each of the parameters. The example with Chang assumed parameters are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70380615",
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness_array = [0.04, 0.12, 0.26, 0.03]\n",
    "density_array = [300, 300, 300, 300]\n",
    "radius_array = [0.4e-3, 0.4e-3, 0.4e-3, 0.4e-3]\n",
    "temperature_array = [260, 260, 260, 260]\n",
    "\n",
    "chang_snowpack = make_snowpack(thickness=thickness_array, microstructure_model='sticky_hard_spheres',\n",
    "                  density=density_array, radius=radius_array, temperature=temperature_array,\n",
    "                  stickiness=0.15) + soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chang_results = model.run(radiometer, chang_snowpack)\n",
    "print (chang_results.TbH().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899284a",
   "metadata": {},
   "source": [
    "Adapt this example to make a more realistic snowpack. Take care to use SI units! Also SMRT layers are numbered from the top down. The thickness array has been done for you, but you'll need to change the other arrays to be more realistic and based on the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942bd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in your own values for density, radius and temperature arrays based on snow_3Feb and temp_data\n",
    "thickness_array = [0.03, 0.26, 0.12, 0.04]\n",
    "density_array = \n",
    "radius_array = \n",
    "temperature_array = \n",
    "\n",
    "realistic_snowpack = make_snowpack(thickness=thickness_array, microstructure_model='sticky_hard_spheres',\n",
    "                  density=density_array, radius=radius_array, temperature=temperature_array,\n",
    "                  stickiness=0.15) + soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f666aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "realistic_results = model.run(radiometer, realistic_snowpack)\n",
    "print (realistic_results.TbH().values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fff5c6",
   "metadata": {},
   "source": [
    "Compare these with the measured values - <mark>does knowing more about the snow properties produce better results? Do the better results get it right for the right reason? Does it matter? What other sources of error are there?</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771fdc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (tb_final.Tb18h[64].values, tb_final.TB36h[64].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f51654",
   "metadata": {},
   "source": [
    "Ideally you need the algorithm to work over all times and at all locations yet be as simple as possible. Simplified parameters and physics is not bad if it works, but the Chang algorithm doesn't as a general rule. A physics-based model can help you understand why an algorithm does or doesn't work. \n",
    "\n",
    "Here around the beginning of February the Chang assumed parameters probably performed better than inputting the measured parameters. This prevented progress in SWE algorithms for a long time, really until objective measurements of grain size became standard practice. The traditional grain sizes here are almost certainly too large, and we didn't even look at the soil properties, although the snowpack may be too deep for it to matter (in which case the algorithm won't work). The small Chang grain radius is compensating for other parameters that are not properly represented either. Besides, even though the simulation of brightness temperature may be good, the algorithm may still not work!\n",
    "\n",
    "Today we use very high resolution microstructure to capture the microwave behaviour at all frequencies, for all snow types and better mathematical modelling of microstructure. For more (very detailed!) information on use of microstructure in microwave modelling, please see Sandells et al. (2021). However, there is still lots more work to be done! Please get in contact with me (melody.sandells@northumbria.ac.uk) if you're interested in collaborating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e342469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
